{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetinAI_ViT\n",
    "\n",
    "Diabetic Retinopathy Classifier using BEiT-2, Attention, and a custom head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'microsoft/beit-base-patch16-224'\n",
    "NUM_CLASSES = 5\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32 # Adjust based on your GPU memory\n",
    "LEARNING_RATE = 1e-5 # Lower learning rate for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is from https://www.kaggle.com/datasets/amanneo/diabetic-retinopathy-resized-arranged, Download and Extract\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset is from https://www.kaggle.com/datasets/amanneo/diabetic-retinopathy-resized-arranged, Download and Extract\")\n",
    "DATA_DIR = '/home/spidey03/Downloads/diabetic-retinopathy-resized-arranged'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Processor for BeiT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "image_mean = processor.image_mean\n",
    "image_std = processor.image_std\n",
    "image_size = processor.size['height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentations for Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    T.Resize((image_size, image_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=image_mean, std=image_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations for Validation & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_transforms = T.Compose([\n",
    "    T.Resize((image_size, image_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=image_mean, std=image_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /home/spidey03/Downloads/diabetic-retinopathy-resized-arranged\n",
      "Found 35126 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "print(f\"Loading data from {DATA_DIR}\")\n",
    "\n",
    "full_dataset = ImageFolder(DATA_DIR)\n",
    "class_names = full_dataset.classes\n",
    "print(f\"Found {len(full_dataset)} images belonging to {len(class_names)} classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 24588\n",
      "Validation set size: 5268\n",
      "Test set size: 5270\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "TRAIN_SPLIT = 0.7\n",
    "VALID_SPLIT = 0.15\n",
    "\n",
    "train_size = int(TRAIN_SPLIT * len(full_dataset))\n",
    "valid_size = int(VALID_SPLIT * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - valid_size\n",
    "\n",
    "train_subset, valid_subset, test_subset = random_split(\n",
    "    full_dataset, [train_size, valid_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_subset)}\")\n",
    "print(f\"Validation set size: {len(valid_subset)}\")\n",
    "print(f\"Test set size: {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Dataset class to Apply correct transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DRDataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = DRDataset(train_subset, transform=train_transforms)\n",
    "valid_dataset = DRDataset(valid_subset, transform=eval_transforms)\n",
    "test_dataset = DRDataset(test_subset, transform=eval_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Class Imbalance with WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öñÔ∏è Addressing class imbalance...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Addressing class imbalance...\")\n",
    "train_labels = [label for _, label in train_subset]\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights = 1. / class_counts\n",
    "sample_weights = np.array([class_weights[t] for t in train_labels])\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.from_numpy(sample_weights).double(),\n",
    "    num_samples=len(train_subset),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DataLoaders created.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"‚úÖ DataLoaders created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Initializing model architecture...\n",
      "‚úÖ Model initialized and moved to device.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BeitModel\n",
    "\n",
    "class BEiTForDRClassification(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(BEiTForDRClassification, self).__init__()\n",
    "        # Load pre-trained BEiT model\n",
    "        self.beit = BeitModel.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        # --- Freeze most layers ---\n",
    "        # Unfreeze only the last 2 layers of the encoder for fine-tuning\n",
    "        for param in self.beit.parameters():\n",
    "            param.requires_grad = False\n",
    "        for layer in self.beit.encoder.layer[-2:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        hidden_size = self.beit.config.hidden_size\n",
    "\n",
    "        # --- Attention Mechanism ---\n",
    "        # This will learn to weigh the importance of different patch embeddings\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8, # A common choice\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # --- Classifier Head ---\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        # BEiT forward pass -> outputs patch embeddings\n",
    "        # Output shape: (batch_size, num_patches + 1, hidden_size)\n",
    "        outputs = self.beit(pixel_values=pixel_values)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "        # Attention mechanism\n",
    "        # MultiheadAttention expects (query, key, value)\n",
    "        # We use the same hidden state for all three\n",
    "        attn_output, _ = self.attention(\n",
    "            last_hidden_state, last_hidden_state, last_hidden_state\n",
    "        )\n",
    "\n",
    "        # We take the output corresponding to the [CLS] token for classification\n",
    "        # The [CLS] token is the first token in the sequence\n",
    "        cls_token_output = attn_output[:, 0]\n",
    "\n",
    "        # Pass through the classifier head\n",
    "        logits = self.classifier(cls_token_output)\n",
    "        return logits\n",
    "\n",
    "print(\"\\nüß† Initializing model architecture...\")\n",
    "model = BEiTForDRClassification(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "print(\"‚úÖ Model initialized and moved to device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluating\")\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "            \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return epoch_loss, {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting model training...\n",
      "\n",
      "--- Epoch 1/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90816df608e442adba01cfc53ccdae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.2233 | Train Acc: 0.4467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091b883bbe104236bd666dc2426060d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Valid Loss: 1.1957 | Valid F1: 0.6110 | Valid Acc: 0.5750\n",
      "‚ú® New best model saved with F1-score: 0.6110\n",
      "\n",
      "--- Epoch 2/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8678c300fcef47f68614aad3b5cec033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.2091 | Train Acc: 0.4607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f239d24b7f384fcba602ddab9f1701eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Valid Loss: 1.2290 | Valid F1: 0.5105 | Valid Acc: 0.4421\n",
      "\n",
      "--- Epoch 3/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38230217eb204b17bcf0bb896bcf258a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.2111 | Train Acc: 0.4510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b74c8fc67f43c39659991102ca1ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Valid Loss: 1.2079 | Valid F1: 0.5169 | Valid Acc: 0.4546\n",
      "\n",
      "--- Epoch 4/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc80585820148d182c6c5b5c12dbac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.1997 | Train Acc: 0.4600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59e2224187d4d20a49894c1caf478e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Valid Loss: 1.2410 | Valid F1: 0.4771 | Valid Acc: 0.4079\n",
      "\n",
      "--- Epoch 5/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf711a9b2c3445fab91795c8c9e9984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.1882 | Train Acc: 0.4648\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fdbc657c634f4ab4fd2b25ae9a9c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Valid Loss: 1.1999 | Valid F1: 0.5278 | Valid Acc: 0.4599\n",
      "\n",
      "--- Epoch 6/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ec5b6a11cb496dbd05526a048f4cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 1.1901 | Train Acc: 0.4696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc545cb4732438282a374f322f6f7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Valid Loss: 1.1904 | Valid F1: 0.5358 | Valid Acc: 0.4694\n",
      "\n",
      "--- Epoch 7/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e5dff349114594b0bb33789fa04093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 1.1883 | Train Acc: 0.4658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce031662f4ca463cb54e4f13fae1bbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Valid Loss: 1.1744 | Valid F1: 0.5707 | Valid Acc: 0.5120\n",
      "\n",
      "--- Epoch 8/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b28c6ea4f943068d0eda5ebe5e806a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 1.1833 | Train Acc: 0.4678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d4b855819844de9a232ed444922131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Valid Loss: 1.2061 | Valid F1: 0.5354 | Valid Acc: 0.4702\n",
      "\n",
      "--- Epoch 9/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a95cac113541138567b8e2b3f48a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.1881 | Train Acc: 0.4665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b83ab3c6cb04987a56d3dcee3631060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Valid Loss: 1.1784 | Valid F1: 0.5758 | Valid Acc: 0.5196\n",
      "\n",
      "--- Epoch 10/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a5aabfa5104c1580afedc70c5d5982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.1764 | Train Acc: 0.4761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56823885cb4c4934b8fc3958373da376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Valid Loss: 1.2276 | Valid F1: 0.5210 | Valid Acc: 0.4552\n",
      "\n",
      "--- Epoch 11/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1e6a5f59f54e498122f1ef8ff6ebaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.1655 | Train Acc: 0.4794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d5cd34d0f34ce3ba03af925893a908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Valid Loss: 1.1881 | Valid F1: 0.5560 | Valid Acc: 0.4937\n",
      "\n",
      "--- Epoch 12/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22436898e9494afc8fe58cb2e33d1a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.1795 | Train Acc: 0.4712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394a4f37030e4b5490706bf5ded59134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Valid Loss: 1.1765 | Valid F1: 0.5752 | Valid Acc: 0.5175\n",
      "\n",
      "--- Epoch 13/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd32f1168fb4cad9bd4d2fb5b0f27fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.1749 | Train Acc: 0.4776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a5c62be32941f69032f0c8d1b1ebd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Valid Loss: 1.1829 | Valid F1: 0.5652 | Valid Acc: 0.5049\n",
      "\n",
      "--- Epoch 14/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c886fc6f1334044aaa92f190da02b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.1734 | Train Acc: 0.4755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca26d1970dd43578120c72704da8d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Valid Loss: 1.1881 | Valid F1: 0.5610 | Valid Acc: 0.4991\n",
      "\n",
      "--- Epoch 15/15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3a03544014a73b5df6dad3c5da67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.1640 | Train Acc: 0.4803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aede63210d1d4f3b9d45e472a94b700b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Valid Loss: 1.1791 | Valid F1: 0.5655 | Valid Acc: 0.5051\n",
      "\n",
      "üèÅ Training finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ Starting model training...\")\n",
    "best_valid_f1 = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_f1': []}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    valid_loss, valid_metrics, _, _ = evaluate(model, valid_loader, criterion, DEVICE)\n",
    "    history['valid_loss'].append(valid_loss)\n",
    "    history['valid_f1'].append(valid_metrics['f1'])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Valid Loss: {valid_loss:.4f} | Valid F1: {valid_metrics['f1']:.4f} | Valid Acc: {valid_metrics['accuracy']:.4f}\")\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    # Model Checkpointing\n",
    "    if valid_metrics['f1'] > best_valid_f1:\n",
    "        best_valid_f1 = valid_metrics['f1']\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"‚ú® New best model saved with F1-score: {best_valid_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüèÅ Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Evaluating model on the test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ddef2af88241a2aef3fedeec355594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Metrics ---\n",
      "Accuracy:  0.5626\n",
      "F1 Score (Weighted): 0.5985\n",
      "Precision (Weighted): 0.6596\n",
      "Recall (Weighted): 0.5626\n",
      "\n",
      "--- Per-Class Metrics ---\n",
      "  Class  Precision    Recall  F1-Score\n",
      "0     0   0.834850  0.669098  0.742841\n",
      "1     1   0.104651  0.120000  0.111801\n",
      "2     2   0.230591  0.243574  0.236905\n",
      "3     3   0.136725  0.637037  0.225131\n",
      "4     4   0.246324  0.638095  0.355438\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\nüìà Evaluating model on the test set...\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "test_loss, test_metrics, test_labels, test_preds = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "print(\"\\n--- Final Test Metrics ---\")\n",
    "print(f\"Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {test_metrics['f1']:.4f}\")\n",
    "print(f\"Precision (Weighted): {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall (Weighted): {test_metrics['recall']:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "f1_per_class = f1_score(test_labels, test_preds, average=None)\n",
    "precision_per_class = precision_score(test_labels, test_preds, average=None)\n",
    "recall_per_class = recall_score(test_labels, test_preds, average=None)\n",
    "\n",
    "print(\"\\n--- Per-Class Metrics ---\")\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision_per_class,\n",
    "    'Recall': recall_per_class,\n",
    "    'F1-Score': f1_per_class\n",
    "})\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
